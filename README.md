# FUN with AI : Virtual Image Drag using Mediapipe Hand Detection

## Index
1. [Overview](#overview)
2. [Setup](#setup)
3. [Documentation](#docs)

<a name="overview"></a>
## Overview
* Build your own basic virtual drag system using Mediapipe Hand Detection
* Python Version:  **Python 3.7.0**

<a name="setup"></a>
## Setup
* **Installing python**
  - [Ubuntu](https://linuxize.com/post/how-to-install-python-3-7-on-ubuntu-18-04/) 
  - [Windows](https://medium.com/@itylergarrett.tag/how-to-install-python-3-7-on-windows-10-pc-the-non-developer-version-b063e1913b39)
    
* **Installing Miniconda3**
  - [Ubuntu](https://docs.conda.io/projects/conda/en/latest/user-guide/install/linux.html)
  - [Windows](https://docs.conda.io/projects/conda/en/latest/user-guide/install/linux.html)
    

* **Setting up virtual environment using conda**
  - `Initialize conda by 'conda activate' or 'conda init' in terminal`
  - `conda env create -f environment.yml`
  - `conda activate mediapipe_env`

* Now, we can use our system after we clone the repo:
    - `git clone https://github.com/Rajeshmarandi3/virtualhanddrag.git`
    - git checkout master
    - to run the server `python virtual_drag.py`
    
<a name="docs"></a>
## Documentation
Documentation is available [here](https://documenter.getpostman.com/view/4093957/SzS7QmWT?version=latest
)